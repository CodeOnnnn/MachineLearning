{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhoLQDkGgdx8"
      },
      "outputs": [],
      "source": [
        "#Make imports\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "import os\n",
        "import seaborn as sns\n",
        "import string\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oSw7Z3UFvjs",
        "outputId": "cfa8d380-1e6c-40b6-84ea-cb72a4111b9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKe9ncQoZfox"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Hindi_English_Truncated_Corpus.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['source'],axis=1,inplace=True)\n",
        "mask = (df['english_sentence'].str.len()>20) & (df['english_sentence'].str.len()<200)\n",
        "df = df.loc[mask]\n",
        "df = df.sample(64000, random_state=1)\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VKzmB8w0wDco",
        "outputId": "54133ac9-0f41-474d-a779-137fe259b6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        english_sentence  \\\n",
              "63241         Indian News Service - National News Agency   \n",
              "81404  In West Bengal , it seems set to eat humble pi...   \n",
              "8803   One american dollar is equal to 60 pakistani r...   \n",
              "73434                      but between those high highs,   \n",
              "65711  Every other politician went along because when...   \n",
              "\n",
              "                                          hindi_sentence  \n",
              "63241     इण्डियन न्यूज सर्विस - राष्ट्रीय समाचार एजेंसी  \n",
              "81404  पश्चिम बंगाल में तो वह अपमान का घूंट पीने को भ...  \n",
              "8803   एक अमरीकी डालर की कीमत लगभग ६० पाकिस्तानी रुपय...  \n",
              "73434                     लेकिन इन बेहतरीन लम्हों के बीच  \n",
              "65711  और वजह यह थी कि आर्थिक मामलं पर हमेशा विफल विच...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07b517b2-77ee-4432-b950-af8656725116\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63241</th>\n",
              "      <td>Indian News Service - National News Agency</td>\n",
              "      <td>इण्डियन न्यूज सर्विस - राष्ट्रीय समाचार एजेंसी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81404</th>\n",
              "      <td>In West Bengal , it seems set to eat humble pi...</td>\n",
              "      <td>पश्चिम बंगाल में तो वह अपमान का घूंट पीने को भ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8803</th>\n",
              "      <td>One american dollar is equal to 60 pakistani r...</td>\n",
              "      <td>एक अमरीकी डालर की कीमत लगभग ६० पाकिस्तानी रुपय...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73434</th>\n",
              "      <td>but between those high highs,</td>\n",
              "      <td>लेकिन इन बेहतरीन लम्हों के बीच</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65711</th>\n",
              "      <td>Every other politician went along because when...</td>\n",
              "      <td>और वजह यह थी कि आर्थिक मामलं पर हमेशा विफल विच...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07b517b2-77ee-4432-b950-af8656725116')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07b517b2-77ee-4432-b950-af8656725116 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07b517b2-77ee-4432-b950-af8656725116');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng = df[\"english_sentence\"]\n",
        "hind = df[\"hindi_sentence\"]\n",
        "eng = eng.apply(lambda x: \"<START> \" + str(x) + \" <END>\")\n",
        "hind = hind.apply(lambda x: \"<START> \"+ x + \" <END>\")\n"
      ],
      "metadata": {
        "id": "DO6IbmpbwHbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "oov_token = '<unk>'\n",
        "eng_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters = filters, oov_token=oov_token)\n",
        "hind_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters = filters, oov_token=oov_token)\n",
        "eng_tokenizer.fit_on_texts(eng)\n",
        "hind_tokenizer.fit_on_texts(hind)"
      ],
      "metadata": {
        "id": "5ZK6rKOkwJrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsf6EbkWZDUY",
        "outputId": "8f914866-12ba-4ef7-d336-4eb8b60b59bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64000 64000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"<START> I'd like to tell you about one such child, <END>\",\n",
              " '<START> मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी, <END>')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "print(len(eng), len(hind))\n",
        "print()\n",
        "eng[:3], hind[:3]\n",
        "eng[1],hind[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjnK8XArDPUe"
      },
      "outputs": [],
      "source": [
        "#Some parameters\n",
        "vocab_size = 52000\n",
        "total_sentences = 30000\n",
        "maxlen = 20\n",
        "epochs = 80\n",
        "validation_split = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyHjYB_eMpD7"
      },
      "outputs": [],
      "source": [
        "en_data = []\n",
        "hi_data = []\n",
        "\n",
        "cnt = 0\n",
        "\n",
        "for (en,hi) in zip(eng, hind):\n",
        "  l = min(len(en.split()), len(hi.split()))\n",
        "  if l <= maxlen:\n",
        "    en_data.append(en)\n",
        "    hi_data.append(hi)\n",
        "    cnt += 1\n",
        "  if cnt == total_sentences:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwR2rlOvB-xZ",
        "outputId": "67f63c38-0d54-490d-8042-7d5bf898329d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Vocab Size:  44305\n",
            "Hindi Vocab Size:  51960\n"
          ]
        }
      ],
      "source": [
        "en_sequences = eng_tokenizer.texts_to_sequences(eng)\n",
        "hi_sequences = hind_tokenizer.texts_to_sequences(hind)\n",
        "english_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "hindi_vocab_size = len(hind_tokenizer.word_index) + 1\n",
        "print(\"English Vocab Size: \", english_vocab_size)\n",
        "print(\"Hindi Vocab Size: \", hindi_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luUa7TE6RYFq"
      },
      "outputs": [],
      "source": [
        "#Prepare encoder data\n",
        "encoder_inputs = tf.keras.preprocessing.sequence.pad_sequences(en_sequences, maxlen=maxlen, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olIjin62TPF7"
      },
      "outputs": [],
      "source": [
        "#Prepare decoder data\n",
        "decoder_inputs = []\n",
        "decoder_outputs = []\n",
        "\n",
        "for hi in hi_sequences:\n",
        "  decoder_inputs.append(hi[:-1])\n",
        "  decoder_outputs.append(hi[1:])\n",
        "\n",
        "decoder_inputs = tf.keras.preprocessing.sequence.pad_sequences(decoder_inputs, maxlen=maxlen, padding='post')\n",
        "decoder_outputs = tf.keras.preprocessing.sequence.pad_sequences(decoder_outputs, maxlen=maxlen, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5OWbUrPRENr",
        "outputId": "f2b6ec13-f2fe-4b50-cf09-19dc1a77ef85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28500, 20) (28500, 20) (28500, 20)\n"
          ]
        }
      ],
      "source": [
        "# Training and Testing split\n",
        "# 95%, 5%\n",
        "split = int(0.95 * total_sentences)\n",
        "\n",
        "X_train = [encoder_inputs[:split], decoder_inputs[:split]]\n",
        "y_train = decoder_outputs[:split]\n",
        "\n",
        "# Test data to evaluate our NMT model using BLEU score\n",
        "X_test = en_data[:split]\n",
        "y_test = hi_data[:split]\n",
        "\n",
        "print(X_train[0].shape, X_train[1].shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwMIxiB9Y0Vx",
        "outputId": "8f9d52ac-7ec5-4072-b9fe-c8c2dd70b7e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[    2,    71,   419, ...,     0,     0,     0],\n",
              "        [ 5505, 11454,    94, ...,  4969,  3537,     3],\n",
              "        [    2,    37,   587, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [    2,     8,    15, ...,     0,     0,     0],\n",
              "        [    2,    89,   741, ...,     0,     0,     0],\n",
              "        [    2,     7,   123, ...,     0,     0,     0]], dtype=int32),\n",
              " array([[    2, 13532,  4759, ...,     0,     0,     0],\n",
              "        [  176, 16315,     4, ...,   121,  2541,     6],\n",
              "        [    2,    13,  1425, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [    2,   197,     5, ...,     0,     0,     0],\n",
              "        [    2,   147,    45, ...,     0,     0,     0],\n",
              "        [    2,  7816,    69, ...,     0,     0,     0]], dtype=int32)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr3oBm5fwCMN",
        "outputId": "018f981e-439d-4a97-e383-0710b6471619"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44305"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "english_vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUboXx8WjDnP",
        "outputId": "531daaf5-98a7-4a12-b553-a618a45671b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 256)    11342080    ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 256)    13301760    ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 256),  525312      ['embedding_1[0][0]',            \n",
            "                                 (None, 256),                     'lstm[0][1]',                   \n",
            "                                 (None, 256)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 51960)  13353720    ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 39,048,184\n",
            "Trainable params: 39,048,184\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "d_model = 256\n",
        "\n",
        "#Encoder\n",
        "inputs = tf.keras.layers.Input(shape=(None,))\n",
        "x = tf.keras.layers.Embedding(english_vocab_size, d_model, mask_zero=True)(inputs)\n",
        "_,state_h,state_c = tf.keras.layers.LSTM(d_model,activation='relu',return_state=True)(x)\n",
        "\n",
        "#Decoder\n",
        "targets = tf.keras.layers.Input(shape=(None,))\n",
        "embedding_layer = tf.keras.layers.Embedding(hindi_vocab_size, d_model, mask_zero=True)\n",
        "x = embedding_layer(targets)\n",
        "decoder_lstm = tf.keras.layers.LSTM(d_model,activation='relu',return_sequences=True, return_state=True)\n",
        "x,_,_ = decoder_lstm(x, initial_state=[state_h, state_c])\n",
        "dense1 = tf.keras.layers.Dense(hindi_vocab_size, activation='softmax')\n",
        "x = dense1(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=[inputs, targets],outputs=x)\n",
        "model.summary()\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "model.compile(optimizer='rmsprop', loss=loss, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq3TUpTK3TRE",
        "outputId": "1d4bdab8-7985-4841-cb5d-7ffbd871168e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 28500, 20)\n",
            "(28500, 20)\n"
          ]
        }
      ],
      "source": [
        "X_train=np.array(X_train)\n",
        "print(X_train.shape)\n",
        "y_train=np.array(y_train)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRd1rrU4BU34"
      },
      "outputs": [],
      "source": [
        "save_model_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='./drive/MyDrive/en-hi.h5',\n",
        "    monitor='val_accuracy',\n",
        "    mode='max'\n",
        ")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxsPj7SL1f-b",
        "outputId": "9370f811-fa9f-45f9-e049-8e42177b75b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "847/847 [==============================] - 178s 200ms/step - loss: 7.2656 - accuracy: 0.1030 - val_loss: 6.7766 - val_accuracy: 0.1254\n",
            "Epoch 2/80\n",
            "847/847 [==============================] - 138s 163ms/step - loss: 6.5990 - accuracy: 0.1355 - val_loss: 6.6762 - val_accuracy: 0.1332\n",
            "Epoch 3/80\n",
            "847/847 [==============================] - 138s 162ms/step - loss: 6.3747 - accuracy: 0.1502 - val_loss: 6.3802 - val_accuracy: 0.1484\n",
            "Epoch 4/80\n",
            "847/847 [==============================] - 136s 161ms/step - loss: 6.2160 - accuracy: 0.1601 - val_loss: 6.4752 - val_accuracy: 0.1440\n",
            "Epoch 5/80\n",
            "847/847 [==============================] - 136s 161ms/step - loss: 6.0839 - accuracy: 0.1713 - val_loss: 6.5732 - val_accuracy: 0.1568\n",
            "Epoch 6/80\n",
            "847/847 [==============================] - 136s 161ms/step - loss: 5.9556 - accuracy: 0.1823 - val_loss: 6.2151 - val_accuracy: 0.1681\n",
            "Epoch 7/80\n",
            "847/847 [==============================] - 135s 160ms/step - loss: 5.8339 - accuracy: 0.1926 - val_loss: 6.2838 - val_accuracy: 0.1741\n",
            "Epoch 8/80\n",
            "847/847 [==============================] - 135s 159ms/step - loss: 5.7187 - accuracy: 0.2027 - val_loss: 6.1355 - val_accuracy: 0.1794\n",
            "Epoch 9/80\n",
            "847/847 [==============================] - 134s 158ms/step - loss: 5.6042 - accuracy: 0.2122 - val_loss: 6.1633 - val_accuracy: 0.1912\n",
            "Epoch 10/80\n",
            "847/847 [==============================] - 134s 158ms/step - loss: 5.4916 - accuracy: 0.2217 - val_loss: 6.1378 - val_accuracy: 0.1937\n",
            "Epoch 11/80\n",
            "847/847 [==============================] - 135s 159ms/step - loss: 5.3827 - accuracy: 0.2307 - val_loss: 6.4532 - val_accuracy: 0.1911\n",
            "Epoch 12/80\n",
            "847/847 [==============================] - 135s 159ms/step - loss: 5.2774 - accuracy: 0.2398 - val_loss: 6.2033 - val_accuracy: 0.1905\n",
            "Epoch 13/80\n",
            "847/847 [==============================] - 134s 158ms/step - loss: 5.1724 - accuracy: 0.2490 - val_loss: 6.4257 - val_accuracy: 0.1930\n",
            "Epoch 14/80\n",
            "847/847 [==============================] - 131s 155ms/step - loss: 5.0716 - accuracy: 0.2578 - val_loss: 6.6313 - val_accuracy: 0.1918\n",
            "Epoch 15/80\n",
            "847/847 [==============================] - 132s 156ms/step - loss: 4.9637 - accuracy: 0.2675 - val_loss: 6.6853 - val_accuracy: 0.1935\n",
            "Epoch 16/80\n",
            "847/847 [==============================] - 133s 157ms/step - loss: 4.8711 - accuracy: 0.2761 - val_loss: 7.0578 - val_accuracy: 0.1904\n",
            "Epoch 17/80\n",
            "847/847 [==============================] - 131s 155ms/step - loss: 4.7752 - accuracy: 0.2851 - val_loss: 6.4152 - val_accuracy: 0.1976\n",
            "Epoch 18/80\n",
            "847/847 [==============================] - 131s 154ms/step - loss: 4.6891 - accuracy: 0.2938 - val_loss: 6.5814 - val_accuracy: 0.2007\n",
            "Epoch 19/80\n",
            "847/847 [==============================] - 135s 159ms/step - loss: 4.5985 - accuracy: 0.3020 - val_loss: 6.6661 - val_accuracy: 0.2012\n",
            "Epoch 20/80\n",
            "847/847 [==============================] - 138s 163ms/step - loss: 4.5076 - accuracy: 0.3110 - val_loss: 6.7888 - val_accuracy: 0.1880\n",
            "Epoch 21/80\n",
            "847/847 [==============================] - 137s 161ms/step - loss: 4.4213 - accuracy: 0.3201 - val_loss: 6.7929 - val_accuracy: 0.2009\n",
            "Epoch 22/80\n",
            "847/847 [==============================] - 137s 162ms/step - loss: 4.3391 - accuracy: 0.3282 - val_loss: 6.9482 - val_accuracy: 0.2023\n",
            "Epoch 23/80\n",
            " 91/847 [==>...........................] - ETA: 2:00 - loss: 4.1322 - accuracy: 0.3466"
          ]
        }
      ],
      "source": [
        "model.fit([X_train[0],X_train[1]], y_train, epochs=epochs, validation_split=validation_split, callbacks=[save_model_callback, tf.keras.callbacks.TerminateOnNaN()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBvZo1SRzHbU"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Retrieve previously saved stuff\n",
        "saved_model = tf.keras.models.load_model('./drive/MyDrive/en-hi.h5')\n",
        "saved_model.summary()\n",
        "\n",
        "inputs = saved_model.get_layer('input_1').output\n",
        "_,state_h,state_c = saved_model.get_layer('lstm').output\n",
        "targets = saved_model.get_layer('input_2').output\n",
        "embedding_layer = saved_model.get_layer('embedding_1')\n",
        "decoder_lstm = saved_model.get_layer('lstm_1')\n",
        "dense1 = saved_model.get_layer('dense')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O0cbyxstbgS"
      },
      "outputs": [],
      "source": [
        "d_model=256\n",
        "#Inference Model\n",
        "\n",
        "#Encoder\n",
        "encoder = tf.keras.models.Model(inputs, [state_h, state_c])\n",
        "\n",
        "#Decoder\n",
        "decoder_input_h = tf.keras.layers.Input(shape=(d_model,))\n",
        "decoder_input_c = tf.keras.layers.Input(shape=(d_model,))\n",
        "x = embedding_layer(targets)\n",
        "x, decoder_output_h, decoder_output_c = decoder_lstm(x, initial_state=[decoder_input_h, decoder_input_c])\n",
        "x = dense1(x)\n",
        "decoder = tf.keras.models.Model([targets] + [decoder_input_h, decoder_input_c],\n",
        "                                [x] + [decoder_output_h, decoder_output_c])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DM4WlWIkXbS4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def predict_sentence(en_input):\n",
        "  input_seq = eng_tokenizer.texts_to_sequences([en_input])\n",
        "  next_h, next_c = encoder.predict(input_seq)\n",
        "\n",
        "  curr_token = np.zeros((1,1))\n",
        "\n",
        "  curr_token[0,0] = 2\n",
        "\n",
        "  pred_sentence = ''\n",
        "\n",
        "  for i in range(maxlen):\n",
        "    output, next_h, next_c = decoder.predict([curr_token] + [next_h, next_c])\n",
        "    next_token = np.argmax(output[0, 0, :])\n",
        "    next_word = hind_tokenizer.index_word[next_token]\n",
        "    if next_word == '<end>':\n",
        "      break\n",
        "    else:\n",
        "      pred_sentence += ' ' + next_word\n",
        "      curr_token[0, 0] = next_token\n",
        "\n",
        "  return pred_sentence\n",
        "\n",
        "\n",
        "e=\"but between those high highs\"\n",
        "h=predict_sentence(e)\n",
        "h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pq5OesbI4pd7"
      },
      "outputs": [],
      "source": [
        "#Testing and Analysis\n",
        "import nltk\n",
        "\n",
        "candidates = []\n",
        "references = []\n",
        "\n",
        "ctr = 3\n",
        "i = 0\n",
        "\n",
        "engtest=[\"in this book the condition of those who died is there\",\"and deal with the subject in a way\",\"politicians do not have permission to do what needs to be done\"]\n",
        "hintest=[\"इसमें तुमसे पूर्व गुज़रे हुए लोगों के हालात हैं\",\" और कैसे इस विषय से निपटें\",\"राजनीतिज्ञों के पास जो कार्य करना चाहिए वह करने कि अनुमति नहीं है\"]\n",
        "gts=[\"इस पुस्तक में मरने वालों की स्थिति है\",\"और एक तरह से विषय से निपटें\",\"राजनेताओं को वह करने की अनुमति नहीं है जो करने की आवश्यकता है\"]\n",
        "while ctr>0:\n",
        "  # l = len(X_test[i].split())\n",
        "  # if l<=maxlen:   #Choose only sentences of length in range [5,15]\n",
        "  pred_sentence = predict_sentence(engtest[i])\n",
        "  candidates.append(pred_sentence.split())\n",
        "\n",
        "  print(\"Input: \", engtest[i])\n",
        "  print(\"Prediction: \", pred_sentence)\n",
        "\n",
        "    #google_translated_sentence = translate_client.translate(X_test[i], target_language='hi')['translatedText']\n",
        "\n",
        "  print(\"Google Translated Reference: \", gts[i])\n",
        "  print(\"Dataset Reference: \", ' '.join(hintest[i].split()[1:-1]))\n",
        "  print()\n",
        "  references.append([hintest[i].split()[1:-1], gts[i].split()])\n",
        "\n",
        "  ctr -= 1\n",
        "  i += 1\n",
        "\n",
        "print(nltk.translate.bleu_score.corpus_bleu(references, candidates))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_6pNldaAKsMH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}